\documentclass[../skript.tex]{subfiles}

\begin{document}
For a Steiner tree $T$ we define $\Loss(T)$ as the shortest spanning subgraph of $T$ where each connected component contains at least one terminal. Moreover, we define $\loss(T)$ as the length of $\Loss(T)$.
\begin{lemma} % Lemma 78
\label{thm:78}
For all Steiner trees $T$:
\[
	\loss(T) \leq \frac{1}{2} c(E(T)).
\]
\end{lemma}
\begin{proof}
Assume $T$ is a binary tree. Select for each Steiner vertex one child using a least cost edge. Then the total weight is at most $\frac{1}{2} c(E(T))$. (Considering a path of length 2 whose endpoints are terminals demonstrates tightness)
\end{proof}
$\Loss(T)$ can be computed in polynomial time: By adding an additional vertex connected to all terminals, it can be computed for instance by \textsc{Prim's Algorithm}.
We define $\mst(R/\Loss(t_1 \ldots t_i))$ as the length of a minimum spanning tree in $G_D(R)$ after contracting the loss of $t_1 \ldots t_i$ in $G$ (note that this value depends on the specific choice of the $\Loss(t_1 \ldots t_i)$, but this is not relevant to the algorithm).
\begin{samepage}
\begin{algorithmbox}[Loss Contraction Algorithm]
\begin{tabular}{@{}ll}
\textit{Input:} & $G = (V, E)$, $R \subseteq V(G)$, $c : E(G) \to \R_+$\\
\textit{Output:} & A Steiner tree for $R$ in $G$
\end{tabular}
\end{algorithmbox}
\vspace{-7pt}
\begin{algorithm}[H]
$i \coloneqq 0$\;
\While{$\exists t_{i+1} \subseteq \R$ such that $3 \leq |t_{i+1}| \leq k$ and $f_i(t_{i+1}) < 1$}{
	choose $t_{i+1} \subseteq R$ with $3 \leq |t_{i+1}| \leq k$ that minimizes $f_i(t_{i+1}) \coloneqq \frac{\loss(t_{i+1})}{\mst(R/\Loss(t_1 \ldots t_i)) - \mst(R/\Loss(t_1 \ldots t_{i+1}))}$\;
	$i \coloneqq i + 1$\;
	$i_{\max} \coloneqq i$\;
}
\Return $\Loss(t_1 \ldots t_{i_{\max}}) \cup \MST(R/\Loss(t_1 \ldots t_{i_{\max}}))$\;
\end{algorithm}
\vspace{-7pt}
\EndAlgorithmLine
\end{samepage}
\begin{theorem}[Robins, Zelikovsky \lbrack{}2005\rbrack{}] % Thm 79
\label{thm:79}
The \textsc{Loss Contraction\\Algorithm} has approximation ratio
\[
	\left( 1 + \frac{\ln 3}{2} \right) \cdot r_k < 1.550 \cdot r_k.
\]
\end{theorem}
\begin{proof}
We need modified version of the contraction Lemma: The edge lengths in $A, B, C$ are not set to 0, but just to some value smaller than the current value.
Let $t_1^*, t_2^*, \ldots, t_p^*$ be the full components of an optimum solution, i.e.\ a minimum $k$-Steiner tree and set
\begin{IEEEeqnarray*}{rCl}
f_i(t) &\coloneqq& \frac{\loss(t)}{\mst(R/\Loss(t_1 \ldots t_i)) - \mst(R/\Loss(t_1 \ldots t_i t))} \\
G_i &=& \mst(R/\Loss(t_1 \ldots t_i)) - \smt_k + \loss_k.
\end{IEEEeqnarray*}
Here, $\loss_k \coloneqq \loss(t_1^* \ldots t_p^*)$. We have $f_i(t_{i+1}) < 1$, $i = 0, \ldots, i_{\max} - 1$.
Then
\begin{IEEEeqnarray*}{rCl}
\min_j f_i(t_j^*) &=& \min_j \frac{\loss(t_j^*)}{\mst(R/\Loss(t_1 \ldots t_i)) - \mst(R/\Loss(t_1 \ldots t_i t_j^*))} \\
&\leq& \min_j \frac{\loss(t_j^*)}{\mst(R/\Loss(t_1 \ldots t_i t_1^* \ldots t_{j-1}^*)) - \mst(R/\Loss(t_1 \ldots t_i t_1^* \ldots t_j^*))} \\
&\leq& \min_j \frac{\sum_{j=1}^p \loss(t_j^*)}{\sum_{j=1}^p \mst(R/\Loss(t_1 \ldots t_i t_1^* \ldots t_{j-1}^*)) - \mst(R/\Loss(t_1 \ldots t_i t_1^* \ldots t_j^*))} \\
&\leq& \frac{\loss_k}{\mst(R/\Loss(t_1 \ldots t_i)) - \mst(R/\Loss(t_1^* \ldots t_p^*))} \\
&=& \frac{\loss_k}{G_i}
\end{IEEEeqnarray*}
By the choice in the algorithm, we get
\[
	f_i(t_{i+1}) \leq \frac{\loss_k}{G_i}.
\]
Moreover, the following bounds hold:
\begin{IEEEeqnarray*}{rClCl}
G_0 &=& \mst(R) - \smt_k + \loss_k &\geq& \loss_k
\end{IEEEeqnarray*}
By what we just derived:
\[
1 \leq \min_j f_{i_{\max}} (t_j^*) \leq \frac{\loss_k}{G_{i_{\max}}},
\]
implying $G_{i_{\max}} \leq \loss_k$.
$\mst(R/\Loss(t_1 \ldots t_i))$ is monotonically decreasing in $i$:
\begin{IEEEeqnarray*}{rCl}
\sum_{i=1}^{i_{\max}} \loss(t_i) &=& \sum_{i=1}^{i_{\max} - 1} f_i(t_{i+1}) \cdot \left( \mst(R/\Loss(t_1 \ldots t_{i-1})) - \mst(R/\Loss(t_1 \ldots t_i)) \right) \\
&\leq& \sum_{i=0}^{i_{\max} - 1} \min \left(1, \frac{\loss_k}{G_i} \right) \left( G_i - G_{i+1} \right) \\
&\leq& \sum_{i=0}^{i_{\max} - 1} \int_{G_{i_{\max}}}^{G_i} \min \left(1, \frac{\loss_k}{x}\right) \dx \\
&=& \int_{G_{i_{\max}}}^{\loss_k} 1 \dx + \int_{\loss_k}^{G_0} \frac{\loss_k}{x} \dx \\
&=& \loss_k - G_{i_{\max}} + \loss_k \cdot \ln \frac{G_0}{\loss_k}
\end{IEEEeqnarray*}
Hence, we have
\begin{IEEEeqnarray*}{rCl}
\mst(R/\Loss(t_1 \ldots t_{i_{\max}})) + \sum_{i=1}^{i_{\max}} \loss(t_i) &\leq& G_{i_{\max}} + \smt_k - \loss_k + \loss_k - G_{i_{\max}} + \loss_k \cdot \ln \frac{G_0}{\loss_k} \\
&=& \smt_k + \loss_k \cdot \ln \frac{G_0}{\loss_k} \\
&=& \smt_k + \loss_k \cdot \frac{\mst(R) - \smt_k + \loss_k}{\loss_k} \\
&\leq& \smt_k \left( 1 + \frac{\loss_k}{\smt_k} \cdot \ln \left( 1 + \frac{\smt_k}{\loss_k} \right) \right) \\
&\leq& \smt_k \left( 1 + \max_{0 \leq x \leq \frac{1}{2}} x \cdot\ln \left( 1 + \frac{1}{x} \right) \right) \\
&=& \smt_k \cdot \left( 1 + \frac{1}{2} \cdot \ln 3 \right).
\end{IEEEeqnarray*}
The maximum's bounds are due to \cref{thm:78}.
\end{proof}
For $G = (V, E)$, $R \subseteq V(G)$, $c : E(G) \to \R_+$ we define a \emph{directed full Steiner tree} as a full Steiner tree with some root vertex $r$ such that all edges are directed to $r$. All other vertices are called sources, and we also call $r$ the sink.
We define $\mathscr{C}_k$ as the set of all directed full components of size at most $k$ with minimum length. Then $|\mathscr{C}_k| \leq \mathcal{O}(n^k \cdot k)$.
We say $C \in \mathscr{C}_k$ \emph{crosses} $U \subseteq R$ if $C$ has at least one source in $U$ and the sink in $R\setminus U$.
Set 
\[
	\delta_k^+(U) = \{ C \in \mathscr{C}_k \midcolon C \text{ crosses } U \}.
\]
Assume $\mathscr{C}_k = \{ C_1, C_2, \ldots \}$ and fix some $r \in R$: \\
Directed-Cut-Formulation ($k$-DCR):
\begin{IEEEeqnarray*}{l}
\min \sum_{j} c(C_j) \cdot x_j \\
\text{\ac{st}} \quad \begin{IEEEeqnarraybox}[][t]{rCl"l}
\sum_{C_j \in \delta_k^+(U)} x_j &\geq& 1 & \forall \emptyset \subset U \subseteq R \setminus \{ r \} \\
x_j &\geq& 0
\end{IEEEeqnarraybox}
\end{IEEEeqnarray*}
$k$-DCR is a relaxation of the $k$-Steiner tree problem: Take $\SMT_k$, select a root $r \in R$, direct all edges towards $r$. Assign 1 to all these directed full components (of size at most $k$).
\begin{lemma} % Lemma 80
\label{thm:80}
The LP $k$-DCR can be solved in polynomial time for fixed $k$.
\end{lemma}
\begin{proof}
It is enough to solve the separation problem, i.e.\ given $x$ find
\[
	\emptyset \subset U \subseteq R \setminus \{ r \} \;\; \text{\ac{st}} \;\; \sum_{C_j \in \delta_k^+(U)} x_j < 1.
\]
We will show: We can find $U$ that minimizes $\sum_{C_j \in \delta_k^+(U)} x_j$.

Let $G = (V, E)$, $R \subseteq V(G)$, $c : E(G) \to \R_+$. Set
\[
	G' = (V', E'), \quad V' \coloneqq R \cup \{ C_j \mid C_j \in \mathscr{C}_k \}.
\]
For each $C_j$: add edges $(u, C_j)$ if $u$ is a source of $C_j$ and edges $e_j = (C_j, v)$ if $v$ is a sink of $C_j$.
The edges $e_j$ are of weight $x_j$, all other edges have infinite weight.

For all $s \in R \setminus \{ r \}$ compute the minimum $s$-$r$-cuts in $G'$.
Let $\delta^+(X)$ be a minimum capacity cut among these $|R| - 1$ cuts.

\underline{Claim:} $U \coloneqq R \cap X$ minimizes $\sum_{C_j \in \delta_k^+(U)} x_j$. \\
$\delta^-(r)$ is an $s$-$r$-cut of finite weight.
Let $\delta^+(X)$ be a minimum $s$-$r$-cut \ac{st} $|X|$ is smallest possible.
We set
\[
	R' \coloneqq X \cap R, \quad \mathscr{C}_k' \coloneqq \mathscr{C}_k \cap X.
\]
Let $e \in \delta^+(X)$, then $w(e) < \infty$. Thus $e = (x, y)$ with $x \in \mathscr{C}_k'$ and $y \notin R'$.
If for some $x \in \mathscr{C}_k'$ no $(z, x)$-edge exists with $z \in R'$, then
\[
	\left( R' \cup \mathscr{C}_k' \right) \setminus \{ x \}
\]
contradicts the choice of $X$.
This implies $\delta^+(X)$ contains exactly the edges $e_j$ for which $C_j$ crosses $R'$.
Then in turn,
\[
	\min_{\emptyset \subset U \subseteq R \setminus \{ r\}} \sum_{C_j \in \delta_k^+(U)} x_j \leq \min_{S \in R \setminus \{ r\}} \{ \text{capacity of an $s$-$r$-cut in $G$} \}.
\]
For a given $U$ with $\emptyset \subset U \subseteq R \setminus \{ r \}$ that minimizes $\sum_{C_j \in \delta_k^+(U)} x_j$ set
\[
	X \coloneqq U \cup \left\{ C_j \midcolon (x, C_j) \in E(G') \text{ for } x \in U \right\}.
\]
This yields
\begin{IEEEeqnarray*}{rCl}
\sum_{C_j \in \delta_k^+(U)} x_j &=& \sum_{e_j : C_j \in \delta_k^+(U)} w(e_j) \\
&=& \sum_{e \in \delta^+(X)} w(e)
\end{IEEEeqnarray*}
In the last step, we used that
\[
	\sum_{e \in \delta^+(X)} w(e) \geq \sum_{e_j : C_j \in \delta_k^+(U)} w(e_j)
\]
as $X$ contains by definition all $C_j$ that cross $U$.
By the definition of $X$, no edge of $\delta^+(U)$ is in $\delta^+(X)$. Hence, $\delta^+(X)$ are the edges crossing $U$.
\end{proof}
Find an approximate solution to DCR (defined as $n$-DCR).
\end{document}